import asyncio
import aiohttp
import aiofiles
import re
import logging
import sys
from pathlib import Path
from typing import List, Dict, Any
import yaml
from tenacity import retry, stop_after_attempt, wait_fixed
from tqdm.asyncio import tqdm  # tqdm –ø–æ–¥–¥–µ—Ä–∂–∏–≤–∞–µ—Ç asyncio –Ω–∞–ø—Ä—è–º—É—é


def setup_logging(config: Dict[str, Any]) -> None:
    log_level = getattr(logging, config.get("level", "INFO").upper())
    log_file = config.get("file", "download.log")
    logging.basicConfig(
        level=log_level,
        format="%(asctime)s [%(levelname)s] %(message)s",
        handlers=[
            logging.FileHandler(log_file, encoding='utf-8'),
            # logging.StreamHandler(sys.stdout) # –ª—É—á—à–µ –Ω–µ –≤—ã–≤–æ–¥–∏—Ç—å –≤ –∫–æ–Ω—Å–æ–ª—å –∏–∑-–∑–∞ –ø—Ä–æ–≥—Ä–µ—Å—Å–±–∞—Ä–∞
        ]
    )


def expand_wildcard_url(template: str) -> List[str]:
    """
    –ü—Ä–µ–æ–±—Ä–∞–∑—É–µ—Ç 'https://ex.com/file_{1..3}.csv' ‚Üí
    ['https://ex.com/file_1.csv', ..., 'https://ex.com/file_3.csv']
    """
    match = re.search(r'\{(\d+)\.\.(\d+)\}', template)
    if not match:
        raise ValueError("–®–∞–±–ª–æ–Ω –¥–æ–ª–∂–µ–Ω —Å–æ–¥–µ—Ä–∂–∞—Ç—å {start..end}, –Ω–∞–ø—Ä–∏–º–µ—Ä {1..10}")

    start_str, end_str = match.groups()
    start, end = int(start_str), int(end_str)
    if start > end:
        raise ValueError("–ù–∞—á–∞–ª–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞ –Ω–µ –º–æ–∂–µ—Ç –±—ã—Ç—å –±–æ–ª—å—à–µ –∫–æ–Ω—Ü–∞")

    # –û–ø—Ä–µ–¥–µ–ª—è–µ–º —à–∏—Ä–∏–Ω—É —Ñ–æ—Ä–º–∞—Ç–∞ (–¥–ª—è –≤–µ–¥—É—â–∏—Ö –Ω—É–ª–µ–π)
    width = len(start_str) if start_str.startswith('0') and len(start_str) > 1 else 0
    urls = []
    for i in range(start, end + 1):
        repl = str(i).zfill(width) if width else str(i)
        url = template[:match.start()] + repl + template[match.end():]
        urls.append(url)
    return urls


@retry(
    stop=stop_after_attempt(3),
    wait=wait_fixed(1),
    reraise=True
)
async def fetch_content(session: aiohttp.ClientSession, url: str) -> bytes:
    async with session.get(url) as resp:
        if resp.status == 200:
            return await resp.read()
        else:
            raise aiohttp.ClientResponseError(
                request_info=resp.request_info,
                history=resp.history,
                status=resp.status,
                message=f"HTTP {resp.status}",
                headers=resp.headers
            )


async def download_file(
        session: aiohttp.ClientSession,
        url: str,
        output_dir: Path,
        semaphore: asyncio.Semaphore,
        chunk_size: int,
        retries_enabled: bool,
        max_attempts: int,
        delay: float
):
    """–°–∫–∞—á–∏–≤–∞–µ—Ç –æ–¥–∏–Ω —Ñ–∞–π–ª —Å –æ–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ–º –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–º–∞"""
    async with semaphore:  # –æ–≥—Ä–∞–Ω–∏—á–∏–≤–∞–µ–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã–µ –∑–∞–ø—Ä–æ—Å—ã
        try:
            if retries_enabled:
                # –ü–∞—Ç—á–∏–º retry-–¥–µ–∫–æ—Ä–∞—Ç–æ—Ä –ø–æ–¥ —Ç–µ–∫—É—â–∏–µ –Ω–∞—Å—Ç—Ä–æ–π–∫–∏
                @retry(
                    stop=stop_after_attempt(max_attempts),
                    wait=wait_fixed(delay),
                    reraise=True
                )
                async def _download():
                    async with session.get(url) as resp:
                        if resp.status != 200:
                            raise aiohttp.ClientResponseError(
                                request_info=resp.request_info,
                                history=resp.history,
                                status=resp.status,
                                message=f"HTTP {resp.status}",
                                headers=resp.headers
                            )
                        filename = url.split('/')[-1]
                        filepath = output_dir / filename
                        async with aiofiles.open(filepath, 'wb') as f:
                            async for chunk in resp.content.iter_chunked(chunk_size):
                                await f.write(chunk)
                        return filepath

                filepath = await _download()
                logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {url} ‚Üí {filepath}")
            else:
                # –ë–µ–∑ –ø–æ–≤—Ç–æ—Ä–æ–≤ ‚Äî –ø—Ä–æ—Å—Ç–∞—è –∑–∞–≥—Ä—É–∑–∫–∞
                async with session.get(url) as resp:
                    if resp.status == 200:
                        filename = url.split('/')[-1]
                        filepath = output_dir / filename
                        async with aiofiles.open(filepath, 'wb') as f:
                            async for chunk in resp.content.iter_chunked(chunk_size):
                                await f.write(chunk)
                        logging.info(f"‚úÖ –£—Å–ø–µ—à–Ω–æ: {url} ‚Üí {filepath}")
                    else:
                        raise aiohttp.ClientResponseError(
                            request_info=resp.request_info,
                            history=resp.history,
                            status=resp.status,
                            message=f"HTTP {resp.status}",
                            headers=resp.headers
                        )

        except Exception as e:
            logging.error(f"‚ùå –û—à–∏–±–∫–∞ –ø—Ä–∏ –∑–∞–≥—Ä—É–∑–∫–µ {url}: {e}")

    return True  # –≤–∞–∂–Ω–æ –¥–ª—è as_completed


async def download_all(config: Dict[str, Any]):
    """–û—Å–Ω–æ–≤–Ω–∞—è —Ñ—É–Ω–∫—Ü–∏—è –∑–∞–≥—Ä—É–∑–∫–∏"""
    dl_cfg = config["download"]
    http_cfg = config["http"]
    urls = expand_wildcard_url(dl_cfg["url_template"])
    output_path = Path(dl_cfg["output_dir"])
    output_path.mkdir(parents=True, exist_ok=True)

    timeout = aiohttp.ClientTimeout(
        total=http_cfg["timeout"]["total"],
        connect=http_cfg["timeout"]["connect"]
    )

    semaphore = asyncio.Semaphore(dl_cfg.get("max_concurrent", 10))
    chunk_size = dl_cfg.get("chunk_size", 8192)

    retry_cfg = http_cfg.get("retries", {})
    retries_enabled = retry_cfg.get("enabled", False)
    max_attempts = retry_cfg.get("max_attempts", 3)
    delay = retry_cfg.get("delay", 1.0)

    async with aiohttp.ClientSession(timeout=timeout) as session:
        # –°–æ–∑–¥–∞—ë–º –∑–∞–¥–∞—á–∏
        tasks = [
            download_file(
                session, url, output_path, semaphore, chunk_size,
                retries_enabled, max_attempts, delay
            )
            for url in urls
        ]

        # –ò—Å–ø–æ–ª—å–∑—É–µ–º tqdm.as_completed –¥–ª—è –æ—Ç—Å–ª–µ–∂–∏–≤–∞–Ω–∏—è –ø—Ä–æ–≥—Ä–µ—Å—Å–∞
        for coro in tqdm.as_completed(
                tasks,
                total=len(tasks),
                desc="–ó–∞–≥—Ä—É–∑–∫–∞ —Ñ–∞–π–ª–æ–≤",
                unit="—Ñ–∞–π–ª",
                bar_format="{l_bar}{bar}| {n_fmt}/{total_fmt} [{elapsed}<{remaining}, {rate_fmt}]"
        ):
            await coro  # –¥–æ–∂–∏–¥–∞–µ–º—Å—è –∑–∞–≤–µ—Ä—à–µ–Ω–∏—è –∫–∞–∂–¥–æ–π –∑–∞–¥–∞—á–∏


def load_config(path: str = "config.yaml") -> Dict[str, Any]:
    with open(path, "r", encoding="utf-8") as f:
        return yaml.safe_load(f)


def main():
    if len(sys.argv) > 1:
        config_path = sys.argv[1]
    else:
        config_path = "config.yaml"

    # if len(sys.argv) < 2:
    #     print("–ò—Å–ø–æ–ª—å–∑–æ–≤–∞–Ω–∏–µ: python download_wildcard.py 'https://example.com/data_{1..5}.csv'")
    #     sys.exit(1)

    config = load_config(config_path)
    setup_logging(config.get("logging", {}))
    try:
        asyncio.run(download_all(config))
        logging.info("‚úÖ –í—Å–µ —Ñ–∞–π–ª—ã –∑–∞–≥—Ä—É–∂–µ–Ω—ã!")
    except KeyboardInterrupt:
        logging.warning("‚ö†Ô∏è –ó–∞–≥—Ä—É–∑–∫–∞ –ø—Ä–µ—Ä–≤–∞–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º (Ctrl+C)")
        print("\n\nüõë –ó–∞–≥—Ä—É–∑–∫–∞ –æ—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–∞.")
        sys.exit(1)
    except Exception as e:
        logging.error(f"–ö—Ä–∏—Ç–∏—á–µ—Å–∫–∞—è –æ—à–∏–±–∫–∞: {e}")
        raise


if __name__ == "__main__":
    main()
